# MNIST Classification from Scratch

## ğŸ“Œ Project Overview

This project implements core Machine Learning classification algorithms **from scratch** and evaluates them on the MNIST handwritten digits dataset.

The goal of this project is to understand how classification models work internally without relying on high-level ML libraries for training.

Implemented Models:
- Perceptron  
- Gaussian Naive Bayes  
- Logistic Regression (Softmax-based)

The project follows a modular, object-oriented ML framework with custom training loops, evaluation metrics, and hyperparameter management.

---

## ğŸ§  Dataset

The project uses the MNIST dataset:

- 60,000 training images  
- 10,000 testing images  
- 10 classes (digits 0â€“9)  
- 28Ã—28 grayscale images  

Each image is flattened into a feature vector before training.

---

## ğŸ— Project Architecture

### 1ï¸âƒ£ Base Model Framework
- `BaseModel` (Abstract class)
- `ClassificationModel` (Abstract subclass)

These enforce:
- `fit(X, y)`
- `predict(X)`

---

### 2ï¸âƒ£ Implemented Models

#### ğŸ”¹ Perceptron
- Gradient-based weight updates
- Configurable learning rate
- Multiple training epochs
- Works well for linearly separable data

#### ğŸ”¹ Gaussian Naive Bayes
- Class-wise mean and variance estimation
- Gaussian likelihood assumption
- Variance smoothing for numerical stability

#### ğŸ”¹ Logistic Regression
- Multiclass softmax implementation
- Gradient descent optimization
- Cross-entropy-based training
- Configurable learning rate and epochs

---

### 3ï¸âƒ£ Data Preparation Pipeline

Custom data processing classes:
- `DataPreparation`
- `MNISTDataPreparation`

Features:
- Train/Validation split
- Optional binarization
- Data transformation
- Conversion to NumPy arrays

---

### 4ï¸âƒ£ Hyperparameter Management

Centralized configuration via:
`HyperParametersAndTransforms`

Used for:
- Model hyperparameters
- Preprocessing configuration

---

### 5ï¸âƒ£ Model Runner

The `RunModel` class handles:
- Model building
- Training
- Validation
- Accuracy computation
- Confusion matrix generation

---

## ğŸ“Š Training & Evaluation

To run evaluation:

```python
if __name__ == "__main__":
    run_eval()
```

The pipeline:
1. Loads MNIST dataset
2. Applies preprocessing
3. Trains each model
4. Computes validation accuracy
5. Evaluates performance

---

## ğŸš€ Key Learning Outcomes

- Implementing ML algorithms from scratch
- Understanding gradient descent mechanics
- Implementing softmax manually
- Computing Gaussian likelihoods
- Designing modular ML systems
- Building structured evaluation pipelines

---

## ğŸ›  Technologies Used

- Python
- NumPy
- Scikit-learn (metrics only)
- Object-Oriented Programming

---

## ğŸ¯ Skills Demonstrated

- Machine Learning fundamentals
- Mathematical model implementation
- Clean code architecture
- Data preprocessing
- Model validation & evaluation

---

## ğŸ“Œ Project Philosophy

This project focuses on understanding machine learning models beyond black-box usage by manually implementing optimization, probability estimation, and prediction logic.
